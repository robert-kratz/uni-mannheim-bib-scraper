{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oXC3fRchMc3"
      },
      "source": [
        "# Roadmap\n",
        "## [DONE] Create primitive model, predicting for only one library (A3)\n",
        "## Create model for all libraries\n",
        "Here we can:\n",
        "1. for-loops to create datasets and train separate models (might be computationally expensive)\n",
        "2. **multi-input: whole dataset + encoded library name => BEST COMPROMISE (faster than the others bc only one model trained and no need to model inter-dependencies => good if we get 5% mae)**\n",
        "3. data of one library + data of all libraries as inputs => better prediction for one library that accounts for inter-dependencies, BUT extremely computationally expensive (more inputs and more models)\n",
        "\n",
        "## Tweak model to improve its accuracy\n",
        "## Create pipeline for receiving data in real-time, once per hour  \n",
        "## 'Integrate' model into the website"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZGqzzwUzrNz"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EGw5IDX0b2I",
        "outputId": "647e9e1e-86bd-4d8a-b849-3300e8c495a5"
      },
      "outputs": [],
      "source": [
        "import tracemalloc\n",
        "tracemalloc.start()\n",
        "\n",
        "import sqlite3\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "from datetime import timedelta\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import timeseries_dataset_from_array\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, GRU, Dense, Concatenate, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "# Mount drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Connect to the database\n",
        "db_path = \"../prisma/dev.db\"\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "# Load pre-trained RNN model???\n",
        "# model = load_model(\"path_to_your_model.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxswYn0pHItg"
      },
      "source": [
        "### Check that Google Colab takes the database accordingly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-58zad-4iHn",
        "outputId": "63053a73-4351-4a8e-aab4-0eac8bf39cf0"
      },
      "outputs": [],
      "source": [
        "#!ls \"/content/drive/MyDrive/BibScraperModel\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2lf-2Wq5kMa",
        "outputId": "bfaf5021-5c19-4b27-ab06-e62495468b21"
      },
      "outputs": [],
      "source": [
        "#cursor = conn.cursor()\n",
        "#cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "#print(cursor.fetchall())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Gq5LMQnHNOz"
      },
      "source": [
        "### Fetch the data function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tBzCX_Nv0b2O"
      },
      "outputs": [],
      "source": [
        "def fetch_latest_data():\n",
        "    query = f\"\"\"\n",
        "        SELECT name, year, month, day, chunk, percentage\n",
        "        FROM BibData\n",
        "    \"\"\"\n",
        "    df = pd.read_sql(query, conn)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NINl5_T0b2P"
      },
      "source": [
        "### DATA FETCHING IDEA: TAKE DIRECTLY ONLY THE DATA FROM THE LAST 1 month or so\n",
        "storage optimization, time efficiency purposes  \n",
        "model could (theoretically) still be good with a dataset of 1 month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mp0umAIM0b2Q",
        "outputId": "80410136-e96a-4750-ffcd-c6de901da8d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>chunk</th>\n",
              "      <th>percentage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ausleihzentrum Schloss Westflügel</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bibliotheks­bereich A3</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bibliotheks­bereich A5</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bibliotheks­bereich Schloss Ehrenhof</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bibliotheks­bereich Schloss Schneckenhof</td>\n",
              "      <td>2024</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>109</td>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137561</th>\n",
              "      <td>Ausleihzentrum Schloss Westflügel</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137562</th>\n",
              "      <td>Bibliotheks­bereich A3</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137563</th>\n",
              "      <td>Bibliotheks­bereich A5</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137564</th>\n",
              "      <td>Bibliotheks­bereich Schloss Ehrenhof</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137565</th>\n",
              "      <td>Bibliotheks­bereich Schloss Schneckenhof</td>\n",
              "      <td>2024</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>100</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137566 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            name  year  month  day  chunk  \\\n",
              "0              Ausleihzentrum Schloss Westflügel  2024      6    2    109   \n",
              "1                         Bibliotheks­bereich A3  2024      6    2    109   \n",
              "2                         Bibliotheks­bereich A5  2024      6    2    109   \n",
              "3           Bibliotheks­bereich Schloss Ehrenhof  2024      6    2    109   \n",
              "4       Bibliotheks­bereich Schloss Schneckenhof  2024      6    2    109   \n",
              "...                                          ...   ...    ...  ...    ...   \n",
              "137561         Ausleihzentrum Schloss Westflügel  2024     12   11    100   \n",
              "137562                    Bibliotheks­bereich A3  2024     12   11    100   \n",
              "137563                    Bibliotheks­bereich A5  2024     12   11    100   \n",
              "137564      Bibliotheks­bereich Schloss Ehrenhof  2024     12   11    100   \n",
              "137565  Bibliotheks­bereich Schloss Schneckenhof  2024     12   11    100   \n",
              "\n",
              "        percentage  \n",
              "0                0  \n",
              "1              100  \n",
              "2              100  \n",
              "3              100  \n",
              "4               91  \n",
              "...            ...  \n",
              "137561          88  \n",
              "137562          98  \n",
              "137563          95  \n",
              "137564         100  \n",
              "137565          93  \n",
              "\n",
              "[137566 rows x 6 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = fetch_latest_data()\n",
        "df = df.drop_duplicates().reset_index(drop=True)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_figSBmzTKD"
      },
      "source": [
        "### Preprocess data into a dictionary with encoded libraries and their occupancy percentages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3t8-T1ChasRA",
        "outputId": "8ca8c8e4-3070-43a1-c89a-31a85a48a5e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{(1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0):        Occupancy\n",
              " 0           0.00\n",
              " 1           0.00\n",
              " 2           0.00\n",
              " 3           0.00\n",
              " 4           0.00\n",
              " ...          ...\n",
              " 27500       1.00\n",
              " 27501       0.93\n",
              " 27502       0.96\n",
              " 27503       0.91\n",
              " 27504       0.88\n",
              " \n",
              " [27505 rows x 1 columns],\n",
              " (0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0):        Occupancy\n",
              " 27505       0.28\n",
              " 27506       0.25\n",
              " 27507       0.25\n",
              " 27508       0.24\n",
              " 27509       0.23\n",
              " ...          ...\n",
              " 55010       1.00\n",
              " 55011       1.00\n",
              " 55012       1.00\n",
              " 55013       0.98\n",
              " 55014       0.98\n",
              " \n",
              " [27510 rows x 1 columns],\n",
              " (0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0,\n",
              "  0.0):        Occupancy\n",
              " 55015       0.49\n",
              " 55016       0.45\n",
              " 55017       0.43\n",
              " 55018       0.38\n",
              " 55019       0.34\n",
              " ...          ...\n",
              " 82527       1.00\n",
              " 82528       1.00\n",
              " 82529       1.00\n",
              " 82530       0.97\n",
              " 82531       0.95\n",
              " \n",
              " [27517 rows x 1 columns],\n",
              " (0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0,\n",
              "  0.0):         Occupancy\n",
              " 82532        0.28\n",
              " 82533        0.24\n",
              " 82534        0.22\n",
              " 82535        0.20\n",
              " 82536        0.18\n",
              " ...           ...\n",
              " 110048       1.00\n",
              " 110049       1.00\n",
              " 110050       1.00\n",
              " 110051       1.00\n",
              " 110052       1.00\n",
              " \n",
              " [27521 rows x 1 columns],\n",
              " (0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  0.0,\n",
              "  1.0):         Occupancy\n",
              " 110053       0.36\n",
              " 110054       0.32\n",
              " 110055       0.26\n",
              " 110056       0.23\n",
              " 110057       0.21\n",
              " ...           ...\n",
              " 137561       1.00\n",
              " 137562       1.00\n",
              " 137563       0.96\n",
              " 137564       0.96\n",
              " 137565       0.93\n",
              " \n",
              " [27513 rows x 1 columns]}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sort the DataFrame by Library, chronologically\n",
        "df = df.sort_values(by=['name', 'year', 'month', 'day', 'chunk']).reset_index(drop=True)\n",
        "\n",
        "# One-hot encode the library names\n",
        "library_names = df['name'].unique().reshape(-1, 1)\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "one_hot_keys = encoder.fit_transform(library_names)\n",
        "\n",
        "# Create the dictionary with one-hot encoded keys\n",
        "data_by_library = {\n",
        "    tuple(one_hot): df[df['name'] == library].drop(columns=['name', 'year', 'month', 'day', 'chunk'])\n",
        "    for one_hot, library in zip(one_hot_keys, library_names.flatten())\n",
        "}\n",
        "\n",
        "# Normalize percentage values with min max scaler\n",
        "# Because of floating-point operation errors, we round\n",
        "for library, data in data_by_library.items():\n",
        "  scaler = MinMaxScaler()\n",
        "  data['Occupancy'] = scaler.fit_transform(data['percentage'].values.reshape(-1, 1)).round(2)\n",
        "  data = data.drop(columns=['percentage'])\n",
        "\n",
        "  # Update the dictionary with the changed DataFrame\n",
        "  data_by_library[library] = data\n",
        "\n",
        "data_by_library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGUzDoT50b2U"
      },
      "source": [
        "### Prepare data for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ahSUsurh0b2T"
      },
      "outputs": [],
      "source": [
        "# We look at 5 days in the past to predict the next value (5 days x 24 hours x 6 chunks = 720 chunks)\n",
        "past = 720\n",
        "\n",
        "# We want to predict one hour ahead\n",
        "future = 6\n",
        "\n",
        "# We sample data every hour - look at it every 6 chunks within the (past, future) timeframe\n",
        "# We do this to reduce the amount of data to process to a manageable size\n",
        "sampling_rate = 6\n",
        "\n",
        "# Define the sequence length:\n",
        "# We actually look at 720 / 6 = 120 timesteps in the past (120 points of past data)\n",
        "sequence_length = int(past / sampling_rate)\n",
        "\n",
        "# 80% train, 20% validation\n",
        "# Note that there is no test data, since we do not actually know the future values to test against\n",
        "split_fraction = 0.8\n",
        "\n",
        "# Get train split index for all dataframes\n",
        "train_split = [int(split_fraction * len(df)) for df in data_by_library.values()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yRUARBOQxNaz"
      },
      "outputs": [],
      "source": [
        "### REFERENCE THE CODE HERE IF REVERTING TO AUTOMATIC DATASET CREATION\n",
        "# # in the end, we only need the percentage data for the model\n",
        "# # because the order of the data, sorted chronologically, already encodes the time dependency\n",
        "# data = df['Percentage'].values\n",
        "\n",
        "# x_train = data[: train_split]\n",
        "# y_train = data[past : train_split + future]\n",
        "\n",
        "# x_val = data[train_split : len(data) - future] # don't go to the end, let the future data be the target\n",
        "# y_val = data[train_split + past :] # offset train_split by future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dk-ltyiOwEod"
      },
      "outputs": [],
      "source": [
        "# Train and validation data containers\n",
        "train_sequences = []\n",
        "val_sequences = []\n",
        "train_library_inputs = []\n",
        "val_library_inputs = []\n",
        "train_targets = []\n",
        "val_targets = []\n",
        "\n",
        "# Process each library\n",
        "for (library_key, data), train_idx in zip(data_by_library.items(), train_split):\n",
        "\n",
        "    # Split into training and validation sets\n",
        "    occupancy = data['Occupancy'].values\n",
        "    train_values = occupancy[:train_idx]\n",
        "    val_values = occupancy[train_idx:]\n",
        "\n",
        "    # Generate training sequences\n",
        "    for i in range(0, len(train_values) - sequence_length - future, sampling_rate):\n",
        "        train_sequences.append(train_values[i:i + sequence_length])\n",
        "        train_library_inputs.append(library_key)\n",
        "        train_targets.append(train_values[i + sequence_length + future - 1])\n",
        "\n",
        "    # Generate validation sequences\n",
        "    for i in range(0, len(val_values) - sequence_length - future, sampling_rate):\n",
        "        val_sequences.append(val_values[i:i + sequence_length])\n",
        "        val_library_inputs.append(library_key)\n",
        "        val_targets.append(val_values[i + sequence_length + future - 1])\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "train_sequences = np.array(train_sequences).reshape(-1, sequence_length, 1)\n",
        "val_sequences = np.array(val_sequences).reshape(-1, sequence_length, 1)\n",
        "train_library_inputs = np.array(train_library_inputs)\n",
        "val_library_inputs = np.array(val_library_inputs)\n",
        "train_targets = np.array(train_targets)\n",
        "val_targets = np.array(val_targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWTDeB3syzUZ"
      },
      "source": [
        "### Build the multi-input model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XddZNHv50b2V"
      },
      "outputs": [],
      "source": [
        "# Define multi-input GRU model\n",
        "def build_multi_input_model(sequence_length, num_libraries):\n",
        "    seq_input = Input(shape=(sequence_length, 1), name=\"sequence_input\")\n",
        "\n",
        "    x = GRU(128, activation=\"tanh\", return_sequences=True)(seq_input)\n",
        "    x = Dropout(0.2)(x)\n",
        "    x = GRU(64, activation=\"tanh\", return_sequences=False)(x)\n",
        "\n",
        "    lib_input = Input(shape=(num_libraries,), name=\"library_input\")\n",
        "    combined = Concatenate()([x, lib_input])\n",
        "\n",
        "    x = Dense(32, activation=\"relu\")(combined)\n",
        "    output = Dense(1, name=\"output\")(x)\n",
        "\n",
        "    model = Model(inputs=[seq_input, lib_input], outputs=output)\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "sequence_length = 120  # Past timesteps (= 720 / 6)\n",
        "num_libraries = len(encoder.categories_[0])  # Number of unique libraries\n",
        "\n",
        "model = build_multi_input_model(sequence_length, num_libraries)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Rv3-nxbH0b2W"
      },
      "outputs": [],
      "source": [
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience = 2)\n",
        "\n",
        "learning_rate_reduction = ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tMsEmqHz2Ir"
      },
      "source": [
        "### Train and validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg-_WPUL0b2W",
        "outputId": "65f59548-c87a-4eb3-bf2e-10466fd472a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 282ms/step - loss: 0.0183 - mae: 0.0808 - val_loss: 0.0169 - val_mae: 0.0747 - learning_rate: 0.0010\n",
            "Epoch 2/3\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 257ms/step - loss: 0.0060 - mae: 0.0457 - val_loss: 0.0146 - val_mae: 0.0618 - learning_rate: 0.0010\n",
            "Epoch 3/3\n",
            "\u001b[1m285/285\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 236ms/step - loss: 0.0055 - mae: 0.0410 - val_loss: 0.0116 - val_mae: 0.0582 - learning_rate: 0.0010\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x1734cdf54f0>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# RNNs usually slow, computationally expensive:\n",
        "# calculations are done sequentially, it all depends on the previous output => no parallelization possible\n",
        "\n",
        "model.fit(\n",
        "    [train_sequences, train_library_inputs],\n",
        "    train_targets,\n",
        "    validation_data=([val_sequences, val_library_inputs], val_targets),\n",
        "    epochs=3,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping, learning_rate_reduction]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current memory usage: 157.72 MB\n",
            "Peak memory usage: 170.40 MB\n"
          ]
        }
      ],
      "source": [
        "# Get current and peak memory usage\n",
        "current, peak = tracemalloc.get_traced_memory()\n",
        "print(f\"Current memory usage: {current / 1024 ** 2:.2f} MB\")\n",
        "print(f\"Peak memory usage: {peak / 1024 ** 2:.2f} MB\")\n",
        "\n",
        "# Stop tracing\n",
        "tracemalloc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "kxswYn0pHItg",
        "2Gq5LMQnHNOz",
        "2NINl5_T0b2P",
        "V_figSBmzTKD"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dlenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
